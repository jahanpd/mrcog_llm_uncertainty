{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/openai_gpt_temp=1.0_reas=False_agg=original_confidence.pkl\n",
      "./data/openai_gpt_temp=1.0_reas=False_checker=gpt_correctness.pkl\n",
      "./data/openai_temp=1.0_reasoning=False_generations.pkl\n",
      "6.5 50.49089366515837 118.3\n"
     ]
    }
   ],
   "source": [
    "from results_utils import *\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "temp = [1.0]\n",
    "reasoning = [False]\n",
    "entailment = [Entail.GPT]\n",
    "checker = [Entail.GPT]\n",
    "oneshot = [True]\n",
    "\n",
    "combinations = list(itertools.product(temp, reasoning, entailment, checker, oneshot))\n",
    "combinations  = [Result(temp=c[0], reasoning=c[1], entailment=c[2], checker=c[3], oneshot=c[4]) for c in combinations]\n",
    "\n",
    "results = Results(combinations, dataset_path=\"/home/jahanpd/Jahan_Subset_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results.get_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>entailment</th>\n",
       "      <th>checker</th>\n",
       "      <th>metric</th>\n",
       "      <th>correctness</th>\n",
       "      <th>part</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_strict</td>\n",
       "      <td>full</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.777274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_relaxed</td>\n",
       "      <td>full</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.718246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_majority</td>\n",
       "      <td>full</td>\n",
       "      <td>0.553167</td>\n",
       "      <td>0.752023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_lowest</td>\n",
       "      <td>full</td>\n",
       "      <td>0.558258</td>\n",
       "      <td>0.743264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_strict</td>\n",
       "      <td>part1</td>\n",
       "      <td>0.571250</td>\n",
       "      <td>0.755262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>part2</td>\n",
       "      <td>0.497934</td>\n",
       "      <td>0.575146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>0.615724</td>\n",
       "      <td>0.656996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>0.473270</td>\n",
       "      <td>0.616106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>short</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.663004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>long</td>\n",
       "      <td>0.514134</td>\n",
       "      <td>0.610434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp  reasoning  entailment     checker      metric  \\\n",
       "0    1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "1    1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "2    1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "3    1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "4    1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "..   ...        ...         ...         ...         ...   \n",
       "64   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "68   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "72   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "76   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "80   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "\n",
       "                 correctness       part       acc       auc  \n",
       "0     cluster_correct_strict       full  0.461538  0.777274  \n",
       "1    cluster_correct_relaxed       full  0.634615  0.718246  \n",
       "2   cluster_correct_majority       full  0.553167  0.752023  \n",
       "3     cluster_correct_lowest       full  0.558258  0.743264  \n",
       "4     cluster_correct_strict      part1  0.571250  0.755262  \n",
       "..                       ...        ...       ...       ...  \n",
       "64        perplexity_correct      part2  0.497934  0.575146  \n",
       "68        perplexity_correct  knowledge  0.615724  0.656996  \n",
       "72        perplexity_correct  reasoning  0.473270  0.616106  \n",
       "76        perplexity_correct      short  0.847826  0.663004  \n",
       "80        perplexity_correct       long  0.514134  0.610434  \n",
       "\n",
       "[63 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>entailment</th>\n",
       "      <th>checker</th>\n",
       "      <th>metric</th>\n",
       "      <th>correctness</th>\n",
       "      <th>part</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_lowest</td>\n",
       "      <td>long</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.712131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>dentropy</td>\n",
       "      <td>cluster_correct_lowest</td>\n",
       "      <td>long</td>\n",
       "      <td>0.503534</td>\n",
       "      <td>0.698202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>long</td>\n",
       "      <td>0.514134</td>\n",
       "      <td>0.610434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>entropy</td>\n",
       "      <td>cluster_correct_lowest</td>\n",
       "      <td>short</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>dentropy</td>\n",
       "      <td>cluster_correct_lowest</td>\n",
       "      <td>short</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.581395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>Entail.GPT</td>\n",
       "      <td>perplexity</td>\n",
       "      <td>perplexity_correct</td>\n",
       "      <td>short</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.663004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp  reasoning  entailment     checker      metric  \\\n",
       "27   1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "55   1.0      False  Entail.GPT  Entail.GPT    dentropy   \n",
       "80   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "23   1.0      False  Entail.GPT  Entail.GPT     entropy   \n",
       "51   1.0      False  Entail.GPT  Entail.GPT    dentropy   \n",
       "76   1.0      False  Entail.GPT  Entail.GPT  perplexity   \n",
       "\n",
       "               correctness   part       acc       auc  \n",
       "27  cluster_correct_lowest   long  0.503534  0.712131  \n",
       "55  cluster_correct_lowest   long  0.503534  0.698202  \n",
       "80      perplexity_correct   long  0.514134  0.610434  \n",
       "23  cluster_correct_lowest  short  0.934783  0.837209  \n",
       "51  cluster_correct_lowest  short  0.934783  0.581395  \n",
       "76      perplexity_correct  short  0.847826  0.663004  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The effect of response length\n",
    "df[\n",
    "   ((df.part == 'short') |\n",
    "   (df.part == 'long')) &\n",
    "   ((df.correctness == \"cluster_correct_lowest\") |\n",
    "   (df.correctness == \"perplexity_correct\"))\n",
    "   ].sort_values('part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The effect of temperature\n",
    "df[(df.entailment == Entail.DEBERTA) &\n",
    "   (df.metric == 'entropy') &\n",
    "   (df.part == 'full') &\n",
    "   (df.reasoning == False) & \n",
    "   (df.correctness == \"cluster_correct_strict\")\n",
    "   ].sort_values('temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The effect of correctness\n",
    "df[(df.entailment == Entail.DEBERTA) &\n",
    "   (df.metric == 'entropy') &\n",
    "   (df.part == 'full') &\n",
    "   (df.reasoning == False) &\n",
    "   (df.temp == 1.0)\n",
    "   ].sort_values('correctness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The effect of reasoning across parts\n",
    "df[(df.entailment == Entail.GPT) &\n",
    "   (df.metric == 'entropy') &\n",
    "   (df.temp == 1.1) &\n",
    "   (df.correctness == \"cluster_correct_strict\")\n",
    "   ].sort_values('part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_aurocs_sem_ent_full_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp 1 | entailment GPT | no reasoning\n",
    "results.plot_aurocs_metrics_standard(\"AUROC (temp=1;LLM entailment;no reasoning)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
